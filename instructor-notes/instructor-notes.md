First week
--Introductions.
--What is data journalism? Group exercise.  Open Google Doc.
--My take on what it is.
-- a reassurance that we're going to write a lot of code in this class, and that they can do this.
-- Explain how class will work: each week, due by end of day Thursday, you'll have a "do on your own lab to complete".
--It will ask you to walk through some basic exercise involving some part of the data journalism pipeline: data acquisition, data cleaning and examination for flaws, data analysis, exploratory data visualization, et cetera.  Each of those will ask you to answer a few questions as part of it.  You'll also do some conceptual readings and post about those on the class forum.  And you'll read a foundational work of data journalism and try to get a sense of how they did the story: where they got the data, how they did it.
-- In class each week, we'll spend part of the time going over the story, doing a novel exercise using the skills you practiced at home, discussing major projects.


Three Major Assignments:
--Opiod
--Data Acquisition Project (Homelessness Data)
--Data Analysis Project (Opioid Data)
--

In class -- work on exercise related to what we went over, where you will do your best to answer a half dozen questions. We'll break down a story.

Discussion -- what is data journalism
Data story --

Each week, assign a story: where did they get the data.  Which paragraphs are dependent on data

https://journalistsresource.org/syllabi/data-journalism-visualization-mapping-ethics-syllabus/

Way to structure class
In class
--Doing exercises designed to impress upon learnings from last class.
--Have them read one data story, find out how they did it and talk about it each week.
--Opiods story in the post is first week.
--Presentations on one story done, and approval.  If it's too similar, I'll ask you to get another one.
https://en.wikipedia.org/wiki/Data_journalism
https://docs.google.com/document/d/18R26TlL9iguN-iv17QjpSqOnUpsYvjqFTQf0tIEMXik/edit

Make an R document for each exercise, so they can work through it.  And have checkpoints where they should make their own code. Host it at github.io in a folder.  And output file.

https://docs.google.com/document/d/13JYB19XekRAV8rSUisZMEjSTM-XPFeRPBwhbUqiWYZQ/edit
https://docs.google.com/document/d/18R26TlL9iguN-iv17QjpSqOnUpsYvjqFTQf0tIEMXik/edit
https://docs.google.com/document/d/13JYB19XekRAV8rSUisZMEjSTM-XPFeRPBwhbUqiWYZQ/edit

Data Acquisition
--Targeted to go after something (homeless data)
--Need new checkpoints for project

Data stories
--standard
--Have them read 7 types of data stories...

--Enterprise joins, now we talking



Analysis
--Opiods, so set up reading related to that.  
--Working on R all semester, after two weeks on Google Sheets (or Excel)
--Enter
--

--Documentation
--APIs
--Databases
--Visualization
--Enterprise Joins
--Raw Data


**Week 1 - August 27**
* Journalistic Data Analysis with spreadsheets
--Basics, Formulas and Functions

**Week 2 - Sept 3**
--Journalistic Data Analysis with Spreadsheets
--Pivot Tables

**Week 3 - Sept 10**
--Data Analysis in R the Tidyverse way
--Setting up environment and basics: R Project, R Markdown, Packages, Reading in data, first basic command in R.

**Week 4 - Sept 17**
--Data Analysis in R
--Repeat first lesson learned in spreadsheets (formulas, etc...)

**Week 5 - Sept 24**
--Data Analysis in R continued
--Repeat pivot tables

**Week 6 - Oct 1**
--Data Analysis in R continued
--Joins and Enterprise Joins

**Week 7 - Oct 8**
--Data Analysis in R continued
--Misc, Working with Date Times, Case When.  

**Week 8 - Oct 15**
--Data Analysis in R continued
--Exploratory Visualization

**Week 9 - Oct 22**
--Data Cleaning

**Week 10 - Oct 29**
--Data Cleaning

**Week 11 - Nov 5**
--Data Acquisition - Working with APIs

**Week 12 - Nov 12**
--Data Acquisition - Working with Databases

**Week 13 - Nov 19**
--Data Acquisition - Web Scraping

**Week 13 - Nov 26**
--Work on final project

**Week 14 - Dec 3**
--Work on final project

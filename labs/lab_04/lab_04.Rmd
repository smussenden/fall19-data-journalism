---
title: "Lab 04 | R continued"
author: "Sean Mussenden"
date: "9/26/2019"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, paged.print=TRUE)
```

## Objective

The purpose of this lab is to continue learning a journalistic approach to data analysis in R. 

We will continue to do things learned in previous labs:

* Writing R code for data analysis and exploration in the R Studio environment, using R projects (.Rproj) and R markdown files (.Rmd).  
* Loading, making sense of analyzing data using the Tidyverse framework of packages by selecting certain columns, sorting and filtering. 
* Working with data on opioid shipments in the U.S.
* Using documentation and additional reporting to guide and check our analysis. 

Today we'll also:

* Learn to do some light data cleaning by renaming column names.
* Learn to create new columns in our data set based on information in other columns.   
* Summarise raw data, calculating min, max, median and mean values, essentially using R to create a pivot table, like we learned in Google Sheets.
* Learn how to integrate our project with GitHub. 

## How this works, tasks, turning it in, getting help

This document is mostly set up for you to follow along and run code that I have written, and listen to me explain it.  

At several points throughout this document, you will see the word **Task**.  

That indicates I'm expecting you to modify the file I've given you, usually by creating a codeblock and writing some custom code. 

When you are finished, you should save your R markdown file and Knit it as an HTML file. 

You should upload it to GitHub, using GitHub desktop, a process that will be explained. 

And the links to your project is what you'll post on ELMS. 

Need help?  You are welcome to do the following things:

* Use Google or search Stack Overflow. Try searching for your error message or translating your problem into basic terms.
* Check out the excellent [R for Data Science](https://r4ds.had.co.nz/index.html)
* Take a look at the [Cheatsheets](https://www.rstudio.com/resources/cheatsheets/) and [Tidyverse documentation](https://www.tidyverse.org/).
  * [RStudio cheatsheet](https://www.rstudio.com/resources/cheatsheets/#ide)
  * [Readr and Tidyr cheatsheet](https://github.com/rstudio/cheatsheets/raw/master/data-import.pdf) and [Readr documentation](https://readr.tidyverse.org/) and [Tidyr documentation](https://tidyr.tidyverse.org/reference/index.html).
  * [Dplyr cheatsheet](https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf) and [Dplyr documentation](https://dplyr.tidyverse.org/)
  * [GitHub desktop help](https://help.github.com/en/desktop/getting-started-with-github-desktop)
* If you're really stuck, message me on ELMS. 

## Setup

Take the following steps to set up your document:

1. Download the ZIP file and open the folder on your desktop. It should contain this document and a data folder with one TSV.
2. Open this file in RStudio.
3. Rename this file "lab_04_FIRSTNAME_LASTNAME.Rmd".
4. Create a new R project inside of this folder, which will set the working directory in this folder.   

## Load Packages

We're loading two packages today: the Tidyverse, and [Janitor](https://github.com/sfirke/janitor), an excellent package for data cleaning. 

**Task**: In the code block below, load the Tidyverse family of packages and the Janitor package.  Since you've never loaded Janitor before, you'll have to install it.     

```{r}

# Install Janitor package
# install.packages('janitor')

# Load Tidyverse and Janitor


```

## Load Data

For this exercise, we will be working with a small subset of the DEA's ARCOS database, which documented shipments of 76 billion opioid pills between 2006 and 2012, during the peak of the opioid epidemic. We will be working with a subset of shipments to Mingo County, West Virginia, which was flooded with hydrocodone and oxycodone during that period.  It received more pills per capita than all but a handful of other counties in the U.S.

The data was obtained after a lengthy legal battle by the Washington Post and the Charleston Gazette-Mail, and released by the Washington Post in raw and aggregated form. [Washington Post "Digging into the DEA's pain pill database" page](https://www.washingtonpost.com/graphics/2019/investigations/dea-pain-pill-database/).

There is one record (row or observation) per transaction (a shipment from a manufacturer to a distributor to a pharmacy. A data dictionary is available here: [ARCOS Registrant Handbook](https://www.deadiversion.usdoj.gov/arcos/handbook/full.pdf).

**Task**: Create a code block below, and write and execute the function to load in the data of shipments to Mingo County, West Virginia and store it as an object called mingo. Write a comment describing what you are doing.  The TSV file is in the data folder. 

```{r}

# Load data and store it as an object called mingo

```

## Examine the Data

**Task**: Use glimpse(), summary() and View() to get a sense of the data.     

```{r}

```

```{r}

```

## Light Cleaning

We're going to get more in-depth on data cleaning as the semester goes on.  It's a critical step, and failure to do it on messy data sets can make it hard to do analysis -- or, even worse, lead to inaccurate results. 

You'll find the [Janitor package](https://github.com/sfirke/janitor) especially useful for cleaning.  One of my favorite things, is it takes messy column names -- inconsistent capitalization, spaces, weird characters -- and cleans them up.

```{r}

# use the clean_names function in janitor to 
mingo <- clean_names(mingo)
```

**Task**: after you execute the clean_names function, use the glimpse function to look at the results of the cleaning, and compare it to the glimpse you did before the cleaning. Notice that they're all lowercase now! 

```{r}
# write out glimpse to look at the results

```

## Create new columns

As we saw in Google Sheets, it's helpful to create new columns based on data in other columns as we do our analysis.  

In the Tidyverse, the mutate() function [link](https://dplyr.tidyverse.org/reference/mutate.html) -- and other related functions -- allow us to do this easily.  

Probably the simplest example: use mutate to simply make a copy of an existing column with a different name. 

This isn't something we do that often, but it will help us understand how mutate works. 

An important note here.  In all of my examples below, I'm taking the original data set and doing something to it, and storing the results as mingo_working. In each subsequent example, I reuse the name mingo_working, meaning I'm overwriting the results each time. At this stage of my analysis, there's not really any downside to doing this.  

As a reminder, I generally only store a query as a new object if it's a) too big to print out nicely below the codeblock or b) I want to create a slice of the data that I'd like to incorporate into future analysis.  

Remember that our data set has a record of a shipment from a manufacturer to a distributor to a pharmacy, with information about each entity. Unfortunately, the columns in our data set don't refer to manufacturers, distributors or pharmacies.  Instead, information about distributors is in columns tagged "reporter." Information about pharmacies (and other similar entities) is labeled "buyer." Information about the manufacturer is in the labeler or company columns.  

The code below is an example of how we might fix that, using mutuate.  It says: create a new column called distributor_dea_no and populate it with the information in reporter_dea_no. 

``` {r}

mingo_working <- mingo %>%
  mutate(distributor_dea_no = reporter_dea_no)
```

By default, it puts our newly created column at the end, so if we wanted to put it at the beginning, we'd combine it with a select statement. 

``` {r}
mingo_working <- mingo %>%
  mutate(distributor_dea_no = reporter_dea_no) %>%
  select(distributor_dea_no, everything())
```

And if we wanted to then remove reporter_dea_no, essentially letting our newly created column take its place, we could do this.

``` {r}
mingo_working <- mingo %>%
  mutate(distributor_dea_no = reporter_dea_no) %>%
  select(distributor_dea_no, everything()) %>%
  select(-reporter_dea_no)
```

That's kind of a complicated way of renaming a column using mutate.  There's an easier way to do that, using a helpful function called rename() [link](https://dplyr.tidyverse.org/reference/select.html), which is a cousin of [select](https://dplyr.tidyverse.org/reference/select.html).

``` {r}
mingo_working <- mingo %>%
  rename(distributor_dea_no = reporter_dea_no)
```

Here's another use case where mutate might help.

Look at the fields describing the location of the pharmacies, under columns that are tagged "buyer."  They're broken into multiple parts. For mapping purposes, it might be useful to put all these things together, to have one address field. It's often called "concatination". There are several functions that will help us do this.  

There's a handy one in the Tidyverse called unite() [link](https://tidyr.tidyverse.org/reference/unite.html).

The code below takes a first crack at creating a complete address field. 

First, it selects only the columns with buyer in the name. 

Then it says to create a new column called buyer_address_complete, and populate it with the information in buyer_address1 and buyer_city. 

``` {r}

mingo_working <- mingo %>%
  select(contains("buyer")) %>%
  unite(buyer_address_complete, buyer_address1, buyer_city, buyer_state, buyer_zip) 

```

Notice that it removed the original rows.  We can add another "argument" to four function, remove = 'F', to say, don't take away original columns.

``` {r}

mingo_working <- mingo %>%
  select(contains("buyer")) %>%
  unite(buyer_address_complete, buyer_address1, buyer_city, buyer_state, buyer_zip, remove = 'F') 

```

By default, it's putting underscores between each column.  We can change it by adding another argument, sep.  In this case, we're saying: add a space between each column. 

``` {r}

mingo_working <- mingo %>%
  select(contains("buyer")) %>%
  unite(buyer_address_complete, buyer_address1, buyer_city, buyer_state, buyer_zip, remove = 'F', sep=" ") 

```

This still isn't ideal though.  It doesn't really look like you'd expect an address to look. 

Ideally, we'd have spaces between some columns and commas between others. 

We can use mutate() and paste0(), which gives us more control.

``` {r}

mingo_working <- mingo %>%
  mutate(buyer_address_complete = paste0(buyer_address1, buyer_city, buyer_state, buyer_zip))

```

Now let's make it pretty.  I'm putting a space between some columns and a comma between others. 

```{r}
mingo_working <- mingo %>%
  mutate(buyer_address_complete = paste0(buyer_address1," ", buyer_city, ", ", buyer_state, " ", buyer_zip))    

```

**Task**: create a codeblock below, and create a new column that builds as complete an address as possible out of the information on the distributors in the data. 


## If Else and Case When

We can also put different values in a newly created column, based on a value in another column. In google sheets, we did this with IF() functions.  Here, we use if_else(), in this case to classify each shipment as large or not large, depending on the number of pills. 

``` {r}

mingo_working <- mingo %>%
  mutate(pills_category = if_else(dosage_unit > 10000, "large shipment", "not large shipment"))

```

What if we want to create three categories: small, medium and large.  Well, just like in sheets, we can nest these "if" functions.  This one says classify greater than 10K pills as a large shipment, greater than 5K as a medium shipment, everything else as small. 

``` {r}

mingo_working <- mingo %>%
  mutate(pills_category = if_else(dosage_unit > 10000, "large shipment", if_else(dosage_unit > 5000, "medium shipment", "small shipment")))

```

That's a little clunky.  And if we're trying to create a bunch of categories, nested if_else can get out of control. That's where case_when helps [link](https://dplyr.tidyverse.org/reference/case_when.html).  Here's the same thing as above, using case_when().

``` {r}

mingo_working <- mingo %>%
  mutate(pills_category = case_when(
    dosage_unit > 10000 ~ "large shipment",
    dosage_unit > 5000 ~ "medium shipment",
    TRUE ~ "small shipment")
  )

```

**Task**: Create a codeblock below.  Use case_when() or if_else() to create a new column called "state_distribution" that looks at the distributor state column.  If distributor state is in West Virginia, this new column should say "in_state_distribution". If it's not in West Virginia, it should say "out_of_state_distribution".   

## Summarizing

Another way we can create new columns is through a process of summarization.  

This is the R equivalent of creating pivot tables. That is to say, we group by like values in one or more columns and then calculate some things based on those groupings. It's a way of synthesizing new knowledge from raw records.   

Here is perhaps the most simple example.  We're grouping by the name of each pharmacy in our database and counting the total number of shipments to each one.

One note: I'm no longer storing these queries as a new object that needs to be viewed in a separate. By aggregating, they return tables that are typically small enough explore in the table that appears below the codeblock. 

``` {r}

mingo %>%
  group_by(buyer_name) %>%
  summarise(shipments = n())

```

We can combine our grouping and summarizing statements with a sort. This orders from highest to lowest by number of shipments.

```{r}

mingo %>%
  group_by(buyer_name) %>%
  summarise(shipments = n()) %>%
  arrange(desc(shipments))

```

And we can use filters, too.  In this case, I'm returning my summary table, but I only want to look at the pharmacies that got the largest number of shipments (over 1,000). In this case, I'm putting the filter after I aggregate.  

```{r}

mingo %>%
  group_by(buyer_name) %>%
  summarise(shipments = n()) %>%
  arrange(desc(shipments)) %>%
  filter(shipments > 1000)
```

Where you put them in the statement matters. I can also filter the raw data BEFORE I group and summarize.  In this case, I'm filtering to only look at shipments of HYDROCODONE before I group and summarize.  And I'm filtering after to look at only larger shipments.  Notice the results are a bit different than the table above. 

```{r}

mingo %>%
  filter(drug_name == "HYDROCODONE") %>%
  group_by(buyer_name) %>%
  summarise(shipments = n()) %>%
  arrange(desc(shipments)) %>%
  filter(shipments > 1000)
```

We can do more than count - a lot more!  Here, I'm taking the count of shipments, but I'm also adding up the total number of pills in all shipments, using sum(), and sorting. 

```{r}
mingo %>%
  group_by(buyer_name) %>%
  summarise(shipments = n(),
            total_pills = sum(dosage_unit) 
            ) %>%
  arrange(desc(total_pills))
```

Here, I'm adding a new summary stat, the average number of pills per shipment. 

```{r}
mingo %>%
  group_by(buyer_name) %>%
  summarise(shipments = n(),
            total_pills = sum(dosage_unit), 
            avg_pills_per_shipment = mean(dosage_unit)
            ) %>%
  arrange(desc(avg_pills_per_shipment))
```

Now I'm adding two new lines, the minimum and maximum number of pills in a single shipment.

```{r}
mingo %>%
  group_by(buyer_name) %>%
  summarise(shipments = n(),
            total_pills = sum(dosage_unit), 
            avg_pills_per_shipment = mean(dosage_unit),
            min_pills_in_shipment = min(dosage_unit),
            max_pills_in_shipment = max(dosage_unit)
            ) %>%
  arrange(desc(max_pills_in_shipment))
```

There are many other summary stats to calculate, including some more advanced ones. The Dplyr [summarize documentation](https://dplyr.tidyverse.org/reference/summarise.html) and [cheatsheet](https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf) help.  

**Task**: copy the last codeblock above and add one line inside of your summarise function, to create a new column with the median pills per shipment. 

Just as in pivot tables, you can also group by more than one row.  We may draw eroneous conclusions just grouping by pharmacy name.  Why? It's possible that two locations have the same name.  Let's group by both name and dea identification number.     

```{r}
mingo %>%
  group_by(buyer_name, buyer_dea_no) %>%
  summarise(shipments = n(),
            total_pills = sum(dosage_unit), 
            avg_pills_per_shipment = mean(dosage_unit),
            min_pills_in_shipment = min(dosage_unit),
            max_pills_in_shipment = max(dosage_unit)
            ) %>%
  arrange(buyer_name)

```

Hmm.  Now we see that there are two "APPALACHIAN, REG HEALTHCARE INC, DBA MATEWAN CLINIC PHARMACY" and two "MEDICINE CABINET PHARMACY" each with a different dea number. Are there two dea numbers for each name because of an error, or because they represent different entities?  Let's add some more columns. 


```{r}

mingo %>%
  group_by(buyer_name, buyer_dea_no, buyer_city) %>%
  summarise(shipments = n(),
            total_pills = sum(dosage_unit), 
            avg_pills_per_shipment = mean(dosage_unit),
            min_pills_in_shipment = min(dosage_unit),
            max_pills_in_shipment = max(dosage_unit)
            ) %>%
  arrange(buyer_name)

```

They both have the same city.  Let's add address info.  

``` {r}
mingo %>%
  group_by(buyer_name, buyer_dea_no, buyer_city, buyer_address1) %>%
  summarise(shipments = n(),
            total_pills = sum(dosage_unit), 
            avg_pills_per_shipment = mean(dosage_unit),
            min_pills_in_shipment = min(dosage_unit),
            max_pills_in_shipment = max(dosage_unit)
            ) %>%
  arrange(buyer_name)
```

Okay.  Appalachian has the same city and address and name, but a different dea number, off by one letter (a vs b).  The Medicine Cabinet has two different addresses, indicating, possibly, two different locations.  We'd need to do some follow up reporting to figure it out.  

Generally speaking, it's better to start by grouping by more things, and then removing some step-by-step, to identify these errors. 

Just as in Google Sheets, we can also rank with one of several rank functions.  dense_rank() gives us a standard ranking.  The default ordering might seem backwards.  The code below calculates the total number of shipments by buyer, and ranks them, then sorts by that rank.  It lists Hurley Drug Company, which had the most shipments, as the 14th -- or lowest -- ranked.  

```{r}
mingo %>%
  group_by(buyer_name) %>%
  summarise(shipments = n()
            ) %>%
  mutate(shipments_rank = dense_rank(shipments)) %>%
  arrange(desc(shipments_rank))

```

Let's rank them the other way. 
  
```{r}
 mingo %>%
  group_by(buyer_name) %>%
  summarise(shipments = n()
            ) %>%
  mutate(shipments_rank = dense_rank(desc(shipments))) %>%
  arrange(shipments_rank)
  

```
  
The tidyverse also has a handy function for caluclating percentage rank.  There are 14 pharmacies listed here, but percent_rank puts the ranking on a scale as a percentage from 0 to 100.  So, we can say Strosnider had more shipments than 90 percent of pharmacies in the county.

```{r}
mingo %>%
  group_by(buyer_name) %>%
  summarise(shipments = n()
            ) %>%
  mutate(shipments_rank = percent_rank(shipments)) %>%
  arrange(desc(shipments_rank))
 
```

We can also calculate percentage of total.  In this case, we want to calculate the total number of pills sent to each pharmacy, and figure out what percentage of all pills sent to the county that represents. Let's start by calculating a) pills sent to each pharmacy, then b) adding a new column with the total number of pills sent to the county as a whole. The last column in the table will have the same value.  


```{r}
mingo %>%
  group_by(buyer_name) %>%
  summarise(pills_per_pharmacy = sum(dosage_unit)) %>%
  mutate(total_pills = sum(pills_per_pharmacy))

```

Now let's create a new column calculating the share for each pharmacy, and sort it on that new column.

```{r}

# For getting rid of scientific notation
options(scipen=999)

mingo %>%
  group_by(buyer_name) %>%
  summarise(pills_per_pharmacy = sum(dosage_unit)) %>%
  mutate(total_pills = sum(pills_per_pharmacy)) %>%
  mutate(pharmacy_percent_total_pills = pills_per_pharmacy/total_pills) %>%
  arrange(desc(pharmacy_percent_total_pills))

```

Let's make it look more like a percentage by multiplying by 100.

```{r}
mingo %>%
  group_by(buyer_name) %>%
  summarise(pills_per_pharmacy = sum(dosage_unit)) %>%
  mutate(total_pills = sum(pills_per_pharmacy)) %>%
  mutate(pharmacy_percent_total_pills = (pills_per_pharmacy/total_pills)*100) %>%
  arrange(desc(pharmacy_percent_total_pills))
```

That number's still unwieldly. Let's round() to two places. 

```{r}
mingo %>%
  group_by(buyer_name) %>%
  summarise(pills_per_pharmacy = sum(dosage_unit)) %>%
  mutate(total_pills = sum(pills_per_pharmacy)) %>%
    mutate(pharmacy_percent_total_pills = round(((pills_per_pharmacy/total_pills)*100),2)) %>%
  arrange(desc(pharmacy_percent_total_pills))
```

## Exercise 

Let's end this exercise with three tasks, designed to replicate some journalistic data analyisis. 

**Task**: Your editor asks you to figure out which manufacturer to distributor to pharmacy pipeline was responsible for the largest number of pills being shipped to Mingo County, West Virginia, as a way to help focus your reporting on the opioid crisis. 

Write a codeblock below that groups by the manufacturer name, distributor name and pharmacy name and calculates the number of pills for each grouping. Sort it highest to lowest by number of pills.  Leave a comment with the answer: what is the most significant combo?

**Task** Being a good data journalist, you operate on the principle that everyone is flawed and you should be extra skeptical of everyone's work -- especially your own.  

You're trying to figure out whether you can really trust the answer you just got. You should always operate from the assumption that you screwed something up. You start scanning through the table your code just output, and you notice a problem with the distributor column: Cardinal Health appears as CARDINAL HEALTH; CARDINAL HEALTH, INC.; and CARDINAL HEALTH 110, LLC.  

You ask yourself, is this the same company?  

Write some code below that would help you figure out whether this is just an error in how they were input, or whether these truly reference different companies?

**Task** Okay, so based on the code you wrote, it appears that these are indeed three different locations, not an error in the way the name was input.  But you still aren't sure if they're owned by the same company.  You call Cardinal Health, and they won't talk to you.  Being a great reporter, with some creative Googling, you find a [document on their website](https://www.cardinalhealth.com/content/dam/corp/web/documents/brochure/CardinalHealth-PharmaLicenses.pdf) that suggests that at least two of three are owned -- or, were at one point -- by Cardinal Health. A DEA spokesperson confirms on the record that all three are owned by Cardinal Health.  

You're more intersted in looking at the company-to-company-to-company pipeline, instead of the location-to-location pipeline.  In order to proceed with your analysis, you'll need to think of a way to clean the data so that all three Cardinal Health facilities have the same name. Otherwise they won't group correctly.  

You don't know exactly how to do this, other than you have a vague idea that you can probably use a case_when() function.  To answer this question, you don't need to write any code.  You just need to be able to describe what you think you could do to solve the problem, in English, below. One (time consuming solution): open the original data file in a text editor and change them by hand.  There's a better way to do this! Describing what you want to do in simple terms lets you ask others for help, or search for help on the web. Put your answer below.

## Submission

Save the R Markdown file.  Knit it to HTML and make sure it compiles correctly. Upload to GitHub, as instructed.  Provide links to GitHub in ELMS.   

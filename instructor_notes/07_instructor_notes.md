enterprise# Session 07 Instructor Notes

Review of Joins
--walk through, inner, outer, left and right joins

Opioid and Death Rates
--More straightforward. Joined opioid deaths, with opioids per person.  Found a high degree of correlation.  Didn't report the correlation coefficent (r) determination coefficent (r2), more descriptive. Highly suggested the two were linked

Speeding Cops
--What did they find?
--How did they do it?
--Sunpass Toll records for cops.
--By joining location of toll booth with time went through toll booth, could calculate speed!   

Data Acquisition Project
--I'll be coming around to talk to you about it.
--Your letters are due as a forum post, using the SPLC generator.  
--DO NOT SEND LETTER yet
--Guidelines: be specific, for now say willing to pay 0, reference phone conversations.

Data Analysis Project
--Will describe in more detail next week.
--It's what we've been building to all semester.
--30 percent of your grade.
--You're going to work with opioid data in more raw form and find a story that we can report out.   
--To that end, we're going to read this week how three local news orgs localized this opioid data, taking very different approaches: one focused on an especially significant neighborhood; one did an enterprise join to focus on racial discrepancies in usage rates; another did an enterprise join with campaign contribution data to look at the politicians propping up the biggest manufacturers.  
--Read and three forum posts.





### Openers

#### Questions ABOUT Lab
* How did we do?  Anyone run into issues that could be helpful to review?
* Questions about the lab you did two weeks ago? Anything people didn't understand? I'll be walking around and you can ask.  
* This week's lab will be posted by end of day tomorrow.  For real.

#### Discussion: why do we use these script files?
* We could use spreadsheets.
* We could just write r code in the console.  

ASK: Why do we do this?
* Allows us to keep track of our work.  If we make an error at any step, we just go back and fix and run it all again? Lets us come back years later.
* Allows our colleagues to feel confident in our work, including our editors who may not be data saavy and our colleagues who may not be data saavy.  True when we explain step by step.
* Allows our work to be easily fact-checked and reproduced by others with data knowledge.
* Makes others feel confident in our methods, including the general public and experts. We can send our files to experts for review.  
* Teaching!!!! THis is the my favorite reason.  We don't learn in a vacuum.  

#### Data acquisition

**Talk to one-on-one**

* Dana: switch assignments.

**Overall notes**

#### IN CLASS ASSIGNMENT
* Walk through setup together.  

Github assignment.  
--This is where we're going to be storing files.
--Serves as your resume.
--Version control.
--create an account and log in.
--create a new repo empty repo with git ignore for r files and readme.
--clone to desktop.
--open up repo in file browser
--create new file for class assignments
--create new file for labs
--create new file for data analysis project
--drag in lab_04 file.  
--go to github desktop.
--show commit message and push.
--Open R markdown file in R studio.
--Make one change.
--Come back to github desktop, new commit and push.
--Now let's go look at it on the web.
--Make a change on the web.  Wouldn't want to do this.  Kind of showing how we might work on multiple computers.  
--Come back to github desktop.  Pull.  Always want to do this.
--How to submit on ELMS.  

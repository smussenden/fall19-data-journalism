---
title: "Class_05 | In-Class Assignment | R Continued"
author: "Sean Mussenden"
date: "10/1/2019"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, paged.print=TRUE)
```

## Objective

The purpose of this in-class assignment is to build on the information you learned in last week's in-class lab:

* Writing R code for data analysis and exploration in the R Studio environment, using R projects (.Rproj) and R markdown files (.Rmd).  
* Loading, cleaning, making sense of and analyzing data using the Tidyverse framework of packages by selecting certain columns, sorting and filtering
* Create new columns in our data set based on information in other columns.   
* Summarizing data by grouping and calculating min, max, median and mean values.    
* Store changes on GitHub.
* Learn how to join together two related data sets on a common field to perform a new kind of analysis, and discuss common problems that arise when doing joins.  
 
## Tasks, Turning it In, Getting Help

At several points throughout this document, you will see the word **Task**.  

This indicates that you need to do something, generally creating a code block and writing custom code.  

When you are finished, you should save your R markdown file and Knit it as an HTML file.

Upload links to your GitHub folder on ELMS. 

Need help?  You are welcome to do the following things:

* Refer to the previous week's lab.
* Use Google or search Stack Overflow. Try searching for your error message or translating your problem into basic terms.
* Check out the excellent [R for Data Science](https://r4ds.had.co.nz/index.html)
* Take a look at the [Cheatsheets](https://www.rstudio.com/resources/cheatsheets/) and [Tidyverse documentation](https://www.tidyverse.org/).
  * [RStudio cheatsheet](https://www.rstudio.com/resources/cheatsheets/#ide)
  * [Readr and Tidyr cheatsheet](https://github.com/rstudio/cheatsheets/raw/master/data-import.pdf) and [Readr documentation](https://readr.tidyverse.org/) and [Tidyr documentation](https://tidyr.tidyverse.org/reference/index.html).
  * [Dplyr cheatsheet](https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf) and [Dplyr documentation](https://dplyr.tidyverse.org/)
  * [Lubridate cheatsheet](https://rawgit.com/rstudio/cheatsheets/master/lubridate.pdf) and [Lubridate documentation](https://lubridate.tidyverse.org/).
  * [GitHub desktop help](https://help.github.com/en/desktop/getting-started-with-github-desktop)
* After you've spent 5 minutes trying to solve the problem on your own, ask your neighbor and if they don't know, ask me!

## Setup

Take the following steps to set up your document:

1. Download the ZIP file and open the folder inside of your GitHub class assignments folder. It should contain this document, class_05.Rmd, and a data folder with several CSVs.
2. Open this file in RStudio.
3. Rename this file "class_05_FIRSTNAME_LASTNAME.Rmd".
4. Create a new R project inside of this folder, which will set the working directory in this folder.   

## Load Packages

**Task**: Create a code block below, and load the packages you'll need for this exercise.  That's the tidyverse, janitor and lubridate. 

```{r}
# If you don't have one or both of these these, use install.packages()

library(tidyverse)
library(janitor)
library(lubridate)
```

## Load Data

For this exercise, we will be working with a small subset of the DEA's ARCOS database, which documented shipments of 76 billion opioid pills between 2006 and 2012, during the peak of the opioid epidemic. 

The data was obtained after a lengthy legal battle by the Washington Post and the Charleston Gazette-Mail, and released by the Washington Post in raw and aggregated form. [Washington Post "Digging into the DEA's pain pill database" page](https://www.washingtonpost.com/graphics/2019/investigations/dea-pain-pill-database/).

A data dictionary is available here: [ARCOS Registrant Handbook](https://www.deadiversion.usdoj.gov/arcos/handbook/full.pdf).

We will be loading in three different data sets today.  The data was obtained by me from the Washington Post's [ARCOS R package](https://cran.r-project.org/web/packages/arcos/readme/README.html), which allows you to easily download larger and more interesting slices of the data than what's available using the web interface.  We'll work with this package in future classes. 

Here's the data we'll be using, all in the data folder

1. buyer_addresses.csv - one record per "buyer" in the United States -- pharmacies and practitioners, typically -- with information about name, address and location, along with a unique id "buyer_dea_no".
2. buyer_totals.csv - one record per buyer, listing the total number of pills sent to that buyer overall between 2006 and 2012.  The only specific identifying information is a unique id, "buyer_dea_no", but the buyer county and buyer state is there.
3. buyer_annual_by_year - one record per buyer per year, listing the total number of pills sent to that buyer in one year, between 2006 and 2012.  Some buyers have seven records, one for each year between 2006 and 2012, while others have fewer.  The only specific identifying information is a unique id, "buyer_dea_no", but the buyer county and buyer state is there.

**Task**: Create a code block below, and write and execute the function to load in the data.  Store each one as an object that is the same as the file name (without .csv, of course). Write a comment describing what you are doing.  

```{r}

# Load buyer_addresses
buyer_addresses <- read_csv("data/buyer_addresses.csv")

# Load buyer_totals 
buyer_totals <- read_csv("data/buyer_totals.csv")

# Load buyer_annual_by_year
buyer_annual_by_year <- read_csv("data/buyer_annual_by_year.csv")

```

## Examine the Data

Now that the data is in, spend some time examining it to get a sense of it using the functions we reviewed previously. These data checks should be routine for you at this point. What information does it contain? What is missing? Are values stored in strange formats?

**Task** Answer the following question in a comment in a code block below.  Look at the data.  The three data sets describe similar things -- buyers -- but have different numbers of records? What's your best guess for why the number of records buyer_annual_by_year is higher than buyer_totals?  What about your best guess for why buyer_addresses is higher than buyer_totals?  


```{r}
# Use view(), glimpse() and summary() to get a sense of the data

# buyer_annual_by_year is data in its more original form.  There are multiple records per buyer per year, in most cases, because there's a record for multiple years.  The buyer_totals adds all the years together, so there's one value per buyer. 

# Why are there more addresses than there are total records? Great question.  The best guess would be that there are lots of places in the data that didn't have any hydrocodone or oxycodone shipments during that period, so they aren't reflected in totals?

```

## Analysis

**Task**: What is the name and location of the pharmacy that had the most pills sent to it between 2006 and 2012? Do some web research and offer your best guess, which you could use as a jumping off point for futher reporting, as to why this pharmacy might have so many.

```{r}

# The name of the pharmacy isn't in the buyer_totals spreadsheet, so we have to join it to buyer_addresses to get that. 
buyer_totals %>%
  left_join(buyer_addresses, by ="buyer_dea_no") %>%
  arrange(desc(total_pills)) %>%
  select(buyer_name, buyer_county = buyer_county.x, buyer_state.x = buyer_state.x, total_pills, everything())

# The VA Consolidated Mail Outpatient Pharmacy had the most pills sent to it between 2006 and 2012, a total of 512.4 million pills. This is a massive facility that fills prescriptions for the Veterans Affairs.  There's one in Charleston, South Carolina. THere's also one in Leavenworth, Kansas.    

```

**Task**: What is the name and location of the practitioner in Maryland that had the most pills sent to them in 2012? Do some web research and offer your best guess, which you could use as a jumping off point for futher reporting, as to why this pharmacy might have so many.

```{r}
buyer_annual_by_year %>%
  left_join(buyer_addresses, by="buyer_dea_no") %>%
  filter(year==2012, buyer_state.x =="MD", buyer_bus_act.x=="PRACTITIONER") %>%
  arrange(desc(dosage_unit))

```


**Task**: Which single pharmacy **location** had the most pills sent to it? Produce the code to answer this question in a codeblock below. 

Hint: you'll need to group by more than just the pharmacy name to answer this question correctly.

Do some quick web research/reporting.  What actions did the DEA and state of Maryland take against this pharmacy? Why did they do it? 

In a comment inside the codeblock, write a paragraph (two to three sentences) that you could drop into a news story that includes the following information: Name and approximate location of the pharmacy; how many pills it received between 2006 and 2012; and a brief description of what actions the DEA and Maryland took against the pharmacy and why. 


``` {r}

baltimore %>%
  group_by(buyer_name, buyer_address1, buyer_zip) %>%
  summarise(total_pills = sum(dosage_unit)) %>%
  arrange(desc(total_pills))

# Between 2006 and 2012, NewCare Home Health Services in East Baltimore received 6.13 million opioid pills, more than any other location in the city, according to DEA data.  In 2008, employees of the pharmacy were convicted for illegally selling opioids over the web. The pharmacy's license was suspended by the DEA and the state of Maryland. 

```

**Task**: What is the name of the distributor that is responsible for sending the most pills to Baltimore City between 2006 and 2012? Produce the code to answer this question in a codeblock below.  

In a comment inside the codeblock, write the following information: the name of the distributor; the number of pills sent between 2006 and 2012; the state where their corporate headquarters is located.   

``` {r}

baltimore %>%
  group_by(reporter_name) %>%
  summarise(total_pills = sum(dosage_unit)) %>%
  arrange(desc(total_pills))

# McKesson Corporation, 58.3 million pills, Texas. 

```

**Task**: Let's look only at shipments sent by the distributor in the answer to the previous question.  Which **single pharmacy location** received the most shipments from that distributor.  Produce the code to answer this question in a codeblock below.  

In a comment inside the codeblock, write the name and address of the buyer and the total number of shipments during the covered period.  What is unique about this pharmacy that might explain the high number of shipments?

``` {r}

baltimore %>%
  filter(reporter_name == "MCKESSON CORPORATION") %>%
  group_by(buyer_name, buyer_address1, buyer_address2) %>%
  summarise(total_shipments = n()) %>%
  arrange(desc(total_shipments))

# Professional Pharmacy Services inside of Sinai Hospital, 6,254 shipments.  It's a hospital pharmacy, which might exp lain the high numers.  Several of the top 10 are hospitals.  

```

**Task**: Of all the pills sent to Baltimore City between 2006 and 2012, which entity had the highest percentage of all pills sent to it. Group only by the name of the pharmacy for this question. Produce your answer in a codeblock below.

In a comment inside the codeblock, put the name of the entity, the percentage of pills it was responsible for, the total number of pills sent to it and the total number of pills sent to the whole city. 


```{r}
baltimore %>%
  group_by(buyer_name) %>%
  summarise(pills_per_pharmacy = sum(dosage_unit)) %>%
  mutate(total_pills = sum(pills_per_pharmacy)) %>%
    mutate(pharmacy_percent_total_pills = round(((pills_per_pharmacy/total_pills)*100),2)) %>%
  arrange(desc(pharmacy_percent_total_pills))

# Rite-Aid of Maryland, Inc., 12.52 percent, 16.7 million pills out of 133.7 million pills sent to whole city. 
```

**Task**: Being a good data journalist who has worked with messy data, you are skeptical that the percentage you got for the last question -- "RITE AID of MARYLAND INC." -- truly represents all shipments to Rite Aid pharmacies in the city.  

In a codeblock below, copy the function you wrote in your previous answer and add a filter at the end that returns only those records that have "RITE" in the name.  In a comment, explain how many different iterations of Rite Aid there are in this data set.  What prevented them from grouping correctly?  

```{r}
baltimore %>%
  group_by(buyer_name) %>%
  summarise(pills_per_pharmacy = sum(dosage_unit)) %>%
  mutate(total_pills = sum(pills_per_pharmacy)) %>%
    mutate(pharmacy_percent_total_pills = round(((pills_per_pharmacy/total_pills)*100),2)) %>%
  arrange(desc(pharmacy_percent_total_pills)) %>%
  filter(str_detect(buyer_name, "RITE"))

# There are three.  Some have commas and periods, some don't, one has T/A at the end. 
```

**Task**: Create a codeblock below that does the following.

* Creates a new column in the data set called "rite_aid_y_n".  In that column, make the value say "rite_aid_y" if the buyer_name column indicates the store is a rite aid.  Make the value say "rite_aid_n" if it's not.  

* Group by the newly created column, allowing us to examine shipments to Rite Aid and shipments to everyone else.   

* Calculates the total number of shipments to each group, the total shipments to the city as a whole, and the percentage of total shipments each group is responsible for. 

In a comment inside the codeblock, explain how many total shipments there were to the city, how many and what percentage went to Rite Aid stores. 

```{r}
baltimore %>%
  mutate(rite_aid_y_n = case_when(
    str_detect(buyer_name, "RITE") ~ "rite_aid_y",
    TRUE ~ "rite_aid_n"
  )) %>%
  group_by(rite_aid_y_n) %>%
  summarise(shipments_per_pharmacy = n()) %>%
  mutate(total_shipments = sum(shipments_per_pharmacy)) %>%
    mutate(pharmacy_percent_total_shipments = round(((shipments_per_pharmacy/total_shipments)*100),2)) %>%
  arrange(desc(pharmacy_percent_total_shipments))
  
  
```

**Task**: Create a summary table with the following information:

* Looks only at Hydrocodone pills
* Creates a new column called "pipeline" with "the pipeline" for each shipment: one manufacturer to one distributor to one pharmacy. Just use the name of each for this. In this new column you create, separate with two hyphens --
* The following summary stats: total shipments, total pills, average pills per shipment, largest shipment (in terms of pills).
* Sort by different summary columns.  

In a comment, write up your findings.  What information would you use to spur additional reporting? 

```{r}
baltimore %>%
  filter(drug_name == "HYDROCODONE") %>%
  mutate(pipeline = paste0(combined_labeler_name, "--",reporter_name,"--",buyer_name)) %>%
  group_by(pipeline) %>%
  summarise(shipments = n(),
            total_pills = sum(dosage_unit), 
            avg_pills_per_shipment = mean(dosage_unit),
            min_pills_in_shipment = min(dosage_unit),
            max_pills_in_shipment = max(dosage_unit)
            ) %>%
  arrange(desc(max_pills_in_shipment))

# Shipments: SpecGx LLC--RITE AID MID-ATLANTIC--RITE AID OF MARYLAND, INC.	9087	
# Total Pills: SpecGx LLC--RITE AID MID-ATLANTIC--RITE AID OF MARYLAND, INC.	2482900	
# Avg Pills Per Shipment: Actavis Pharma, Inc.--CARDINAL HEALTH--NEWCARE HOME HEALTH SERVICES 14285.0746
# Max Pills Per Shipment: Actavis Pharma, Inc.--CARDINAL HEALTH--NEWCARE HOME HEALTH SERVICES 48000
```


**Task**: The discovery, in the previous question, that there was at least one shipment of Hydrocodone from Actavis Pharma to Cardinal Health to NewCare Home Health Services of 48,000 pills prompts you to want to learn more.  On what date did this transactions take place? Write the code you'd use in a codeblock below. In a comment, put the date.

``` {r}
baltimore %>%
  filter(drug_name == "HYDROCODONE") %>%
  filter(dosage_unit == 48000) %>%
  mutate(pipeline = paste0(combined_labeler_name, "--",reporter_name,"--",buyer_name)) %>%
  select(pipeline, transaction_date, dosage_unit, everything())

# March 21 2006

```

## Your own questions

**Task**: Based on your initial analysis, NewCare Home Health Services seems worthy of additional digging.  You set out to learn as much as you can about their patterns.  Use everything you've learned to get at these or other questions:What were their buying patterns like?  Did they concentrate on buying certain kinds of pills? Were they buying greater numbers of high dose opioids, compared to others? Who made most of the pills they got?  Who distributed them?


Create four separate codeblocks below. Ask and answer at least four separate questions.  

## Output

**Task**: Spellcheck your document in R Studio.  Save your file.  Knit it to an HTML document, making sure it compiles.  Open it in a browser to be sure. Push your changes to GitHub, and go to GitHub.com to make sure your changes got up to the browser. 

## Submission

**Task**: On ELMS, post link to GitHub to the R Markdown file and html file. 